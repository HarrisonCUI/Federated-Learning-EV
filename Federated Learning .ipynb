{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 联邦学习基础架构研究\n",
    "### by 崔凌枫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 背景：数据割裂、数据孤岛，成了限制人工智能发展的瓶颈。联邦学习是避免数据与平台垄断和尊重保护个人隐私解决思路\n",
    "\n",
    "#### 本研究项目是为了通过研究现有federated learning 架构为大型企业提供高质量的预测模型升级服务同时为算法推理平台研发提供思路\n",
    "\n",
    "## 什么是联邦学习\n",
    "\n",
    "举例来说，假设有两个不同的企业 A 和 B，它们拥有不同数据。比\n",
    "如，企业 A 有用户特征数据；企业 B 有产品特征数据和标注数据。这两个企业按照上述 GDPR\n",
    "准则是不能粗暴地把双方数据加以合并的，因为数据的原始提供者，即他们各自的用户并没\n",
    "有机会来同意这样做。假设双方各自建立一个任务模型，每个任务可以是分类或预测，而这\n",
    "些任务也已经在获得数据时有各自用户的认可。那现在的问题是如何在 A 和 B 各端建立高\n",
    "质量的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](chart1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图，第一部分：加密样本对齐。由于两家企业的用户群体并非完全重合，系统利用基于加密\n",
    "的用户样本对齐技术，在 A 和 B 不公开各自数据的前提下确认双方的共有用户，并且不暴露\n",
    "不互相重叠的用户。 以便联合这些用户的特征进行建模。\n",
    "第二部分：加密模型训练。在确定共有用户群体后，就可以利用这些数据训练机器学习\n",
    "模型。为了保证训练过程中数据的保密性，需要借助第三方协作者 C 进行加密训练。以线性\n",
    "回归模型为例，训练过程可分为以下 4 步（如图 2b 所示）：\n",
    " 第①步：协作者 C 把公钥分发给 A 和 B，用以对训练过程中需要交换的数据进行加\n",
    "密；\n",
    " 第②步：A 和 B 之间以加密形式交互用于计算梯度的中间结果；\n",
    " 第③步：A 和 B 分别基于加密的梯度值进行计算，同时 B 根据其标签数据计算损失，\n",
    "并把这些结果汇总给 C。C 通过汇总结果计算总梯度并将其解密。\n",
    " 第④步：C 将解密后的梯度分别回传给 A 和 B；A 和 B 根据梯度更新各自模型的参\n",
    "数。\n",
    "迭代上述步骤直至损失函数收敛，这样就完成了整个训练过程。在样本对齐及模型训练\n",
    "过程中，A 和 B 各自的数据均保留在本地，且训练中的数据交互也不会导致数据隐私泄露。\n",
    "因此，双方在联邦学习的帮助下得以实现合作训练模型。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于研究故利用python syft 进行数据加密， 分别在两台设备上使用pytorch模型进行加密数据的交互后，进行预测模型的升级。验证代码如下： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.fl import utils\n",
    "from syft.workers.websocket_client import WebsocketClientWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1261427b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预设训练参数 训练次数100 epoch   样本数 8 btach size\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.test_batch_size = 8\n",
    "        self.batch_size = 8\n",
    "        self.log_interval = 10\n",
    "        self.seed = 1\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据 鉴于公司数据敏感性这里使用开源的波士顿房价作为演示数据 \n",
    "\n",
    "with open('./data/boston_housing.pickle','rb') as f:\n",
    "    ((x, y), (x_test, y_test)) = pickle.load(f)\n",
    "\n",
    "x = torch.from_numpy(x).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "\n",
    "mean = x.mean(0, keepdim=True)\n",
    "dev = x.std(0, keepdim=True)\n",
    "mean[:, 3] = 0.\n",
    "dev[:, 3] = 1.\n",
    "x = (x - mean) / dev\n",
    "x_test = (x_test - mean) / dev\n",
    "train = TensorDataset(x, y)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2719, -0.4830, -0.4352,  ...,  1.1471,  0.4475,  0.8242],\n",
      "        [-0.4029,  2.9881, -1.3323,  ..., -1.7161,  0.4314, -1.3276],\n",
      "        [ 0.1248, -0.4830,  1.0271,  ...,  0.7835,  0.2203, -1.3069],\n",
      "        ...,\n",
      "        [-0.4015,  0.9896, -0.7406,  ..., -0.7162,  0.0793, -0.6769],\n",
      "        [-0.1727, -0.4830,  1.2443,  ..., -1.7161, -0.9864,  0.4203],\n",
      "        [-0.4037,  2.0414, -1.2001,  ..., -1.3071,  0.2329, -1.1525]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15.2000, 42.3000, 50.0000, 21.1000, 17.7000, 18.5000, 11.3000, 15.6000,\n",
      "        15.6000, 14.4000, 12.1000, 17.9000, 23.1000, 19.9000, 15.7000,  8.8000,\n",
      "        50.0000, 22.5000, 24.1000, 27.5000, 10.9000, 30.8000, 32.9000, 24.0000,\n",
      "        18.5000, 13.3000, 22.9000, 34.7000, 16.6000, 17.5000, 22.3000, 16.1000,\n",
      "        14.9000, 23.1000, 34.9000, 25.0000, 13.9000, 13.1000, 20.4000, 20.0000,\n",
      "        15.2000, 24.7000, 22.2000, 16.7000, 12.7000, 15.6000, 18.4000, 21.0000,\n",
      "        30.1000, 15.1000, 18.7000,  9.6000, 31.5000, 24.8000, 19.1000, 22.0000,\n",
      "        14.5000, 11.0000, 32.0000, 29.4000, 20.3000, 24.4000, 14.6000, 19.5000,\n",
      "        14.1000, 14.3000, 15.6000, 10.5000,  6.3000, 19.3000, 19.3000, 13.4000,\n",
      "        36.4000, 17.8000, 13.5000, 16.5000,  8.3000, 14.3000, 16.0000, 13.4000,\n",
      "        28.6000, 43.5000, 20.2000, 22.0000, 23.0000, 20.7000, 12.5000, 48.5000,\n",
      "        14.6000, 13.4000, 23.7000, 50.0000, 21.7000, 39.8000, 38.7000, 22.2000,\n",
      "        34.9000, 22.5000, 31.1000, 28.7000, 46.0000, 41.7000, 21.0000, 26.6000,\n",
      "        15.0000, 24.4000, 13.3000, 21.2000, 11.7000, 21.7000, 19.4000, 50.0000,\n",
      "        22.8000, 19.7000, 24.7000, 36.2000, 14.2000, 18.9000, 18.3000, 20.6000,\n",
      "        24.6000, 18.2000,  8.7000, 44.0000, 10.4000, 13.2000, 21.2000, 37.0000,\n",
      "        30.7000, 22.9000, 20.0000, 19.3000, 31.7000, 32.0000, 23.1000, 18.8000,\n",
      "        10.9000, 50.0000, 19.6000,  5.0000, 14.4000, 19.8000, 13.8000, 19.6000,\n",
      "        23.9000, 24.5000, 25.0000, 19.9000, 17.2000, 24.6000, 13.5000, 26.6000,\n",
      "        21.4000, 11.9000, 22.6000, 19.6000,  8.5000, 23.7000, 23.1000, 22.4000,\n",
      "        20.5000, 23.6000, 18.4000, 35.2000, 23.1000, 27.9000, 20.6000, 23.7000,\n",
      "        28.0000, 13.6000, 27.1000, 23.6000, 20.6000, 18.2000, 21.7000, 17.1000,\n",
      "         8.4000, 25.3000, 13.8000, 22.2000, 18.4000, 20.7000, 31.6000, 30.5000,\n",
      "        20.3000,  8.8000, 19.2000, 19.4000, 23.1000, 23.0000, 14.8000, 48.8000,\n",
      "        22.6000, 33.4000, 21.1000, 13.6000, 32.2000, 13.1000, 23.4000, 18.9000,\n",
      "        23.9000, 11.8000, 23.3000, 22.8000, 19.6000, 16.7000, 13.4000, 22.2000,\n",
      "        20.4000, 21.8000, 26.4000, 14.9000, 24.1000, 23.8000, 12.3000, 29.1000,\n",
      "        21.0000, 19.5000, 23.3000, 23.8000, 17.8000, 11.5000, 21.7000, 19.9000,\n",
      "        25.0000, 33.4000, 28.5000, 21.4000, 24.3000, 27.5000, 33.1000, 16.2000,\n",
      "        23.3000, 48.3000, 22.9000, 22.8000, 13.1000, 12.7000, 22.6000, 15.0000,\n",
      "        15.3000, 10.5000, 24.0000, 18.5000, 21.7000, 19.5000, 33.2000, 23.2000,\n",
      "         5.0000, 19.1000, 12.7000, 22.3000, 10.2000, 13.9000, 16.3000, 17.0000,\n",
      "        20.1000, 29.9000, 17.2000, 37.3000, 45.4000, 17.8000, 23.2000, 29.0000,\n",
      "        22.0000, 18.0000, 17.4000, 34.6000, 20.1000, 25.0000, 15.6000, 24.8000,\n",
      "        28.2000, 21.2000, 21.4000, 23.8000, 31.0000, 26.2000, 17.4000, 37.9000,\n",
      "        17.5000, 20.0000,  8.3000, 23.9000,  8.4000, 13.8000,  7.2000, 11.7000,\n",
      "        17.1000, 21.6000, 50.0000, 16.1000, 20.4000, 20.6000, 21.4000, 20.6000,\n",
      "        36.5000,  8.5000, 24.8000, 10.8000, 21.9000, 17.3000, 18.9000, 36.2000,\n",
      "        14.9000, 18.2000, 33.3000, 21.8000, 19.7000, 31.6000, 24.8000, 19.4000,\n",
      "        22.8000,  7.5000, 44.8000, 16.8000, 18.7000, 50.0000, 50.0000, 19.5000,\n",
      "        20.1000, 50.0000, 17.2000, 20.8000, 19.3000, 41.3000, 20.4000, 20.5000,\n",
      "        13.8000, 16.5000, 23.9000, 20.6000, 31.5000, 23.3000, 16.8000, 14.0000,\n",
      "        33.8000, 36.1000, 12.8000, 18.3000, 18.7000, 19.1000, 29.0000, 30.1000,\n",
      "        50.0000, 50.0000, 22.0000, 11.9000, 37.6000, 50.0000, 22.7000, 20.8000,\n",
      "        23.5000, 27.9000, 50.0000, 19.3000, 23.9000, 22.6000, 15.2000, 21.7000,\n",
      "        19.2000, 43.8000, 20.3000, 33.2000, 19.9000, 22.5000, 32.7000, 22.0000,\n",
      "        17.1000, 19.0000, 15.0000, 16.1000, 25.1000, 23.7000, 28.7000, 37.2000,\n",
      "        22.6000, 16.4000, 25.0000, 29.8000, 22.1000, 17.4000, 18.1000, 30.3000,\n",
      "        17.5000, 24.7000, 12.6000, 26.5000, 28.7000, 13.3000, 10.4000, 24.4000,\n",
      "        23.0000, 20.0000, 17.8000,  7.0000, 11.8000, 24.4000, 13.8000, 19.4000,\n",
      "        25.2000, 19.4000, 19.4000, 29.1000])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc4 = nn.Linear(24, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "#模拟设备使用者 A 与 B （bob 与 Alice）\n",
    "hook = sy.TorchHook(torch)\n",
    "bob_worker = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice_worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "# kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook}\n",
    "# alice = WebsocketClientWorker(id='alice', port=8779, **kwargs_websocket)\n",
    "# bob = WebsocketClientWorker(id='bob', port=8778, **kwargs_websocket)\n",
    "compute_nodes = [bob_worker, alice_worker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向模拟使用者发送远程数据\n",
    "remote_dataset = (list(), list())\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = Net()\n",
    "alices_model = Net()\n",
    "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)\n",
    "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [bobs_model, alices_model]\n",
    "optimizers = [bobs_optimizer, alices_optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=24, bias=True)\n",
       "  (fc4): Linear(in_features=24, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, target, model, optimizer):\n",
    "    model.send(data.location)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(data)\n",
    "    loss = F.mse_loss(prediction.view(-1), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    for data_index in range(len(remote_dataset[0])-1):\n",
    "        for remote_index in range(len(compute_nodes)):\n",
    "            data, target = remote_dataset[remote_index][data_index]\n",
    "            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n",
    "        for model in models:\n",
    "            model.get()\n",
    "        return utils.federated_avg({\n",
    "            \"bob\": models[0],\n",
    "            \"alice\": models[1]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(federated_model):\n",
    "    federated_model.eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        output = federated_model(data)\n",
    "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item()\n",
    "        predection = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number 1\n",
      "Test set: Average loss: 615.8278\n",
      "Communication time over the network 0.11 s\n",
      "\n",
      "Epoch Number 2\n",
      "Test set: Average loss: 613.6289\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 3\n",
      "Test set: Average loss: 610.8525\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 4\n",
      "Test set: Average loss: 607.9232\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 5\n",
      "Test set: Average loss: 604.9781\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 6\n",
      "Test set: Average loss: 602.0598\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 7\n",
      "Test set: Average loss: 599.1488\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 8\n",
      "Test set: Average loss: 596.2221\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 9\n",
      "Test set: Average loss: 593.2520\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 10\n",
      "Test set: Average loss: 590.2224\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 11\n",
      "Test set: Average loss: 587.1091\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 12\n",
      "Test set: Average loss: 583.8926\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 13\n",
      "Test set: Average loss: 580.5557\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 14\n",
      "Test set: Average loss: 577.0765\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 15\n",
      "Test set: Average loss: 573.4352\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 16\n",
      "Test set: Average loss: 569.6040\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 17\n",
      "Test set: Average loss: 565.5632\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 18\n",
      "Test set: Average loss: 561.2831\n",
      "Communication time over the network 0.24 s\n",
      "\n",
      "Epoch Number 19\n",
      "Test set: Average loss: 556.7154\n",
      "Communication time over the network 0.11 s\n",
      "\n",
      "Epoch Number 20\n",
      "Test set: Average loss: 551.8287\n",
      "Communication time over the network 0.08 s\n",
      "\n",
      "Epoch Number 21\n",
      "Test set: Average loss: 546.5705\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 22\n",
      "Test set: Average loss: 540.8796\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 23\n",
      "Test set: Average loss: 534.6752\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 24\n",
      "Test set: Average loss: 527.8565\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 25\n",
      "Test set: Average loss: 520.3152\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 26\n",
      "Test set: Average loss: 511.9150\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 27\n",
      "Test set: Average loss: 502.4826\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 28\n",
      "Test set: Average loss: 491.8018\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 29\n",
      "Test set: Average loss: 479.5735\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 30\n",
      "Test set: Average loss: 465.3832\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 31\n",
      "Test set: Average loss: 448.7991\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 32\n",
      "Test set: Average loss: 429.2040\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 33\n",
      "Test set: Average loss: 405.8127\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 34\n",
      "Test set: Average loss: 377.8264\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 35\n",
      "Test set: Average loss: 344.3854\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 36\n",
      "Test set: Average loss: 304.8530\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 37\n",
      "Test set: Average loss: 259.4683\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 38\n",
      "Test set: Average loss: 210.3587\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 39\n",
      "Test set: Average loss: 162.4481\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 40\n",
      "Test set: Average loss: 122.8936\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 41\n",
      "Test set: Average loss: 96.7920\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 42\n",
      "Test set: Average loss: 82.9358\n",
      "Communication time over the network 0.09 s\n",
      "\n",
      "Epoch Number 43\n",
      "Test set: Average loss: 76.2781\n",
      "Communication time over the network 0.11 s\n",
      "\n",
      "Epoch Number 44\n",
      "Test set: Average loss: 72.7867\n",
      "Communication time over the network 0.09 s\n",
      "\n",
      "Epoch Number 45\n",
      "Test set: Average loss: 70.5361\n",
      "Communication time over the network 0.11 s\n",
      "\n",
      "Epoch Number 46\n",
      "Test set: Average loss: 68.9330\n",
      "Communication time over the network 0.13 s\n",
      "\n",
      "Epoch Number 47\n",
      "Test set: Average loss: 67.5992\n",
      "Communication time over the network 0.1 s\n",
      "\n",
      "Epoch Number 48\n",
      "Test set: Average loss: 66.4083\n",
      "Communication time over the network 0.13 s\n",
      "\n",
      "Epoch Number 49\n",
      "Test set: Average loss: 65.3180\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 50\n",
      "Test set: Average loss: 64.2877\n",
      "Communication time over the network 0.08 s\n",
      "\n",
      "Epoch Number 51\n",
      "Test set: Average loss: 63.3141\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 52\n",
      "Test set: Average loss: 62.3876\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 53\n",
      "Test set: Average loss: 61.4981\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 54\n",
      "Test set: Average loss: 60.6435\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 55\n",
      "Test set: Average loss: 59.8251\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 56\n",
      "Test set: Average loss: 59.0407\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 57\n",
      "Test set: Average loss: 58.2781\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 58\n",
      "Test set: Average loss: 57.5338\n",
      "Communication time over the network 0.12 s\n",
      "\n",
      "Epoch Number 59\n",
      "Test set: Average loss: 56.8279\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 60\n",
      "Test set: Average loss: 56.1354\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 61\n",
      "Test set: Average loss: 55.4626\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 62\n",
      "Test set: Average loss: 54.8033\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 63\n",
      "Test set: Average loss: 54.1732\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 64\n",
      "Test set: Average loss: 53.5623\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 65\n",
      "Test set: Average loss: 52.9653\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 66\n",
      "Test set: Average loss: 52.3816\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 67\n",
      "Test set: Average loss: 51.8223\n",
      "Communication time over the network 0.1 s\n",
      "\n",
      "Epoch Number 68\n",
      "Test set: Average loss: 51.2816\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 69\n",
      "Test set: Average loss: 50.7554\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 70\n",
      "Test set: Average loss: 50.2426\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 71\n",
      "Test set: Average loss: 49.7441\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 72\n",
      "Test set: Average loss: 49.2661\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 73\n",
      "Test set: Average loss: 48.8044\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 74\n",
      "Test set: Average loss: 48.3548\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 75\n",
      "Test set: Average loss: 47.9030\n",
      "Communication time over the network 0.07 s\n",
      "\n",
      "Epoch Number 76\n",
      "Test set: Average loss: 47.4720\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 77\n",
      "Test set: Average loss: 47.0545\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 78\n",
      "Test set: Average loss: 46.6433\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 79\n",
      "Test set: Average loss: 46.2404\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 80\n",
      "Test set: Average loss: 45.8404\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 81\n",
      "Test set: Average loss: 45.4649\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 82\n",
      "Test set: Average loss: 45.0982\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 83\n",
      "Test set: Average loss: 44.7320\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 84\n",
      "Test set: Average loss: 44.4494\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 85\n",
      "Test set: Average loss: 44.0800\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 86\n",
      "Test set: Average loss: 43.7343\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 87\n",
      "Test set: Average loss: 43.4088\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 88\n",
      "Test set: Average loss: 43.1473\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 89\n",
      "Test set: Average loss: 42.8142\n",
      "Communication time over the network 0.06 s\n",
      "\n",
      "Epoch Number 90\n",
      "Test set: Average loss: 42.4894\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 91\n",
      "Test set: Average loss: 42.2626\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 92\n",
      "Test set: Average loss: 41.9549\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 41.6637\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 94\n",
      "Test set: Average loss: 41.4593\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 95\n",
      "Test set: Average loss: 41.1787\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 96\n",
      "Test set: Average loss: 40.9285\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 97\n",
      "Test set: Average loss: 40.7471\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 98\n",
      "Test set: Average loss: 40.4833\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 99\n",
      "Test set: Average loss: 40.2277\n",
      "Communication time over the network 0.05 s\n",
      "\n",
      "Epoch Number 100\n",
      "Test set: Average loss: 40.0888\n",
      "Communication time over the network 0.05 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(args.epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch Number {epoch + 1}\")\n",
    "    federated_model = train()\n",
    "    model = federated_model\n",
    "    test(federated_model)\n",
    "    total_time = time.time() - start_time\n",
    "    print('Communication time over the network', round(total_time, 2), 's\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
